import streamlit as st
from src.services.pinecone_service import PineconeService
import pandas as pd
import json
import traceback
from datetime import datetime
import tiktoken

# éƒ½é“åºœçœŒã¨å¸‚åŒºç”ºæ‘ã®ãƒ‡ãƒ¼ã‚¿
PREFECTURES = [
    "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ"
]

# ä¸»è¦ãªå¸‚åŒºç”ºæ‘ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ã¨ã—ã¦æ±äº¬éƒ½ã®åŒºã‚’è¨˜è¼‰ï¼‰
CITIES = {
    "åŸ¼ç‰çœŒ": [
        "å·è¶Šå¸‚", "ã•ã„ãŸã¾å¸‚"
    ],
    # ä»–ã®éƒ½é“åºœçœŒã®å¸‚åŒºç”ºæ‘ã‚‚åŒæ§˜ã«è¿½åŠ å¯èƒ½
}

def split_property_data(property_data: dict, max_tokens: int = 3000) -> list:
    """ç‰©ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹"""
    encoding = tiktoken.encoding_for_model("text-embedding-3-large")
    
    # åŸºæœ¬æƒ…å ±ï¼ˆå¸¸ã«å«ã‚ã‚‹ï¼‰
    base_info = {
        "property_name": property_data["property_name"],
        "property_type": property_data["property_type"],
        "prefecture": property_data["prefecture"],
        "city": property_data["city"],
        "detailed_address": property_data["detailed_address"],
        "latitude": property_data.get("latitude", "0.0"),
        "longitude": property_data.get("longitude", "0.0")
    }
    
    # è©³ç´°æƒ…å ±ã‚’åˆ†å‰²
    details = property_data.get("property_details", "")
    if not details:
        return [{"text": json.dumps(base_info, ensure_ascii=False), "metadata": base_info}]
    
    # è©³ç´°æƒ…å ±ã‚’æ®µè½ã§åˆ†å‰²
    paragraphs = [p.strip() for p in details.split('\n') if p.strip()]
    
    # æ®µè½ã‚’æ„å‘³ã®ã‚ã‚‹å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    chunks = []
    current_chunk = []
    current_length = 0
    
    for paragraph in paragraphs:
        # æ®µè½ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        paragraph_tokens = len(encoding.encode(paragraph))
        
        # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«è¿½åŠ ã—ãŸå ´åˆã®é•·ã•ã‚’è¨ˆç®—
        if current_chunk:
            test_text = "\n".join(current_chunk + [paragraph])
        else:
            test_text = paragraph
        
        test_tokens = len(encoding.encode(test_text))
        
        # ãƒãƒ£ãƒ³ã‚¯ã®é•·ã•ãŒåˆ¶é™ã‚’è¶…ãˆã‚‹å ´åˆã€æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
        if test_tokens > max_tokens:
            if current_chunk:
                # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
                chunk_info = base_info.copy()
                chunk_info["property_details"] = "\n".join(current_chunk)
                chunk_info["chunk_number"] = len(chunks) + 1
                
                # ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ç¢ºèª
                chunk_text = json.dumps(chunk_info, ensure_ascii=False)
                chunk_tokens = len(encoding.encode(chunk_text))
                
                if chunk_tokens > max_tokens:
                    # ãƒãƒ£ãƒ³ã‚¯ãŒå¤§ãã™ãã‚‹å ´åˆã¯ã€ã•ã‚‰ã«å°ã•ãåˆ†å‰²
                    sub_chunks = []
                    current_sub_chunk = []
                    current_sub_length = 0
                    
                    for p in current_chunk:
                        p_tokens = len(encoding.encode(p))
                        if current_sub_length + p_tokens > max_tokens // 2:
                            if current_sub_chunk:
                                sub_chunks.append(current_sub_chunk)
                            current_sub_chunk = [p]
                            current_sub_length = p_tokens
                        else:
                            current_sub_chunk.append(p)
                            current_sub_length += p_tokens
                    
                    if current_sub_chunk:
                        sub_chunks.append(current_sub_chunk)
                    
                    # ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
                    for j, sub_group in enumerate(sub_chunks):
                        sub_chunk_info = base_info.copy()
                        sub_chunk_info["property_details"] = "\n".join(sub_group)
                        sub_chunk_info["chunk_number"] = len(chunks) + 1
                        sub_chunk_info["sub_chunk_number"] = j + 1
                        sub_chunk_info["total_sub_chunks"] = len(sub_chunks)
                        
                        chunk = {
                            "text": json.dumps(sub_chunk_info, ensure_ascii=False),
                            "metadata": sub_chunk_info
                        }
                        chunks.append(chunk)
                else:
                    chunk = {
                        "text": chunk_text,
                        "metadata": chunk_info
                    }
                    chunks.append(chunk)
            
            # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
            current_chunk = [paragraph]
            current_length = paragraph_tokens
        else:
            current_chunk.append(paragraph)
            current_length = test_tokens
    
    # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
    if current_chunk:
        chunk_info = base_info.copy()
        chunk_info["property_details"] = "\n".join(current_chunk)
        chunk_info["chunk_number"] = len(chunks) + 1
        
        # ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ç¢ºèª
        chunk_text = json.dumps(chunk_info, ensure_ascii=False)
        chunk_tokens = len(encoding.encode(chunk_text))
        
        if chunk_tokens > max_tokens:
            # ãƒãƒ£ãƒ³ã‚¯ãŒå¤§ãã™ãã‚‹å ´åˆã¯ã€ã•ã‚‰ã«å°ã•ãåˆ†å‰²
            sub_chunks = []
            current_sub_chunk = []
            current_sub_length = 0
            
            for p in current_chunk:
                p_tokens = len(encoding.encode(p))
                if current_sub_length + p_tokens > max_tokens // 2:
                    if current_sub_chunk:
                        sub_chunks.append(current_sub_chunk)
                    current_sub_chunk = [p]
                    current_sub_length = p_tokens
                else:
                    current_sub_chunk.append(p)
                    current_sub_length += p_tokens
            
            if current_sub_chunk:
                sub_chunks.append(current_sub_chunk)
            
            # ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ
            for j, sub_group in enumerate(sub_chunks):
                sub_chunk_info = base_info.copy()
                sub_chunk_info["property_details"] = "\n".join(sub_group)
                sub_chunk_info["chunk_number"] = len(chunks) + 1
                sub_chunk_info["sub_chunk_number"] = j + 1
                sub_chunk_info["total_sub_chunks"] = len(sub_chunks)
                
                chunk = {
                    "text": json.dumps(sub_chunk_info, ensure_ascii=False),
                    "metadata": sub_chunk_info
                }
                chunks.append(chunk)
        else:
            chunk = {
                "text": chunk_text,
                "metadata": chunk_info
            }
            chunks.append(chunk)
    
    # ç·ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’æ›´æ–°
    for chunk in chunks:
        chunk["metadata"]["total_chunks"] = len(chunks)
    
    return chunks

def render_property_upload(pinecone_service: PineconeService):
    """ç‰©ä»¶æƒ…å ±ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UIã‚’è¡¨ç¤º"""
    st.title("ğŸ  ç‰©ä»¶æƒ…å ±ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    with st.form("property_upload_form"):
        st.markdown("### ç‰©ä»¶æƒ…å ±ã®å…¥åŠ›")
        
        # ç‰©ä»¶å
        property_name = st.text_input("ç‰©ä»¶å", help="ç‰©ä»¶ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # ç‰©ä»¶ç¨®åˆ¥
        property_type = st.selectbox(
            "ç‰©ä»¶ç¨®åˆ¥",
            ["ä¸€æˆ¸å»ºã¦", "åœŸåœ°", "ãƒãƒ³ã‚·ãƒ§ãƒ³"],
            help="ç‰©ä»¶ã®ç¨®åˆ¥ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        # éƒ½é“åºœçœŒã¨å¸‚åŒºç”ºæ‘ã®é¸æŠ
        col1, col2 = st.columns(2)
        with col1:
            prefecture = st.selectbox(
                "éƒ½é“åºœçœŒ",
                PREFECTURES,
                help="ç‰©ä»¶ã®æ‰€åœ¨åœ°ã®éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        
        with col2:
            # é¸æŠã•ã‚ŒãŸéƒ½é“åºœçœŒã«åŸºã¥ã„ã¦å¸‚åŒºç”ºæ‘ã®ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
            cities = CITIES.get(prefecture, [])
            city = st.selectbox(
                "å¸‚åŒºç”ºæ‘",
                cities,
                help="ç‰©ä»¶ã®æ‰€åœ¨åœ°ã®å¸‚åŒºç”ºæ‘ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        
        # è©³ç´°ä½æ‰€
        detailed_address = st.text_input("è©³ç´°ä½æ‰€", help="ç‰©ä»¶ã®è©³ç´°ãªä½æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # ç‰©ä»¶ã®è©³ç´°æƒ…å ±
        property_details = st.text_area(
            "ç‰©ä»¶ã®è©³ç´°æƒ…å ±",
            help="ç‰©ä»¶ã®è©³ç´°ãªæƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆé•·ã„æ–‡ç« ã¯è‡ªå‹•çš„ã«åˆ†å‰²ã•ã‚Œã¾ã™ï¼‰"
        )
        
        # ç·¯åº¦ãƒ»çµŒåº¦
        col3, col4 = st.columns(2)
        with col3:
            latitude = st.text_input(
                "ç·¯åº¦",
                value="0.0",
                help="ç‰©ä»¶ã®ç·¯åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
        with col4:
            longitude = st.text_input(
                "çµŒåº¦",
                value="0.0",
                help="ç‰©ä»¶ã®çµŒåº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        submit_button = st.form_submit_button("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        if submit_button:
            try:
                # å¿…é ˆé …ç›®ã®ãƒã‚§ãƒƒã‚¯
                if not all([property_name, property_type, prefecture, city]):
                    st.error("âŒ å¿…é ˆé …ç›®ï¼ˆç‰©ä»¶åã€ç‰©ä»¶ç¨®åˆ¥ã€éƒ½é“åºœçœŒã€å¸‚åŒºç”ºæ‘ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    return
                
                # ç‰©ä»¶æƒ…å ±ã®æ§‹é€ åŒ–
                property_data = {
                    "property_name": property_name,
                    "property_type": property_type,
                    "prefecture": prefecture,
                    "city": city,
                    "detailed_address": detailed_address,
                    "property_details": property_details,
                    "latitude": latitude,
                    "longitude": longitude
                }
                
                # ç‰©ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
                chunks = split_property_data(property_data)
                
                # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«IDã‚’ä»˜ä¸
                timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                for i, chunk in enumerate(chunks):
                    chunk["id"] = f"property_{timestamp}_{i}"
                
                # Pineconeã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                pinecone_service.upload_chunks(chunks, namespace="property")
                
                st.success(f"âœ… ç‰©ä»¶æƒ…å ±ã‚’{len(chunks)}ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
                
            except Exception as e:
                st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                st.error(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {type(e).__name__}")
                st.error(f"ğŸ“œ ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:\n{traceback.format_exc()}") 